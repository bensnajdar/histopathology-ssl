name: SimSiam::Encoder::HOpt::30E::ASHA::ResNet50::LearnedDims
description: Check for LR, Scheduler
labels: [simsiam, encoder, resnet50, kather, hopt]
data:
  worker: 4
hyperparameters:
  # -- dataset
  dataset: kather_h5_224_norm  
  dataset_val: kather_h5_224_norm_split_90_10  
  train_augmentation: 
    type: categorical
    vals:
    - moco_v2
    - medium_stack
  val_augmentation: plain
  img_rescale_size: 96
  normalize_data: True
  # -- model
  method: simsiam
  encoder: resnet50 
  # feature_dim: 2048
  # pred_hidden_dim: 512
  feature_dim: 
    type: categorical
    vals:
    - 2048
    - 1024
    - 512
  pred_hidden_dim:
    type: categorical
    vals:
    - 512
    - 256
    - 128
  # -- optimizer
  momentum:
      type: double
      minval: 0.2
      maxval: 0.9
  lr:
    type: double
    minval: 0.01
    maxval: 2.0
  weight_decay:
      type: double
      minval: 1.0e-7
      maxval: 1.0e-3
  use_lars: 
    type: categorical
    vals:
    - false
    - true
  use_scheduler: 
    type: categorical
    vals: 
    - true
    - false
  # -- training 
  global_batch_size: 256
  freeze_pred: 99000 
  # -- evaluation
  additional_eval: 22500
  use_knn: True
searcher:
  name: adaptive_asha
  metric: v_loss
  smaller_is_better: true
  max_length:
         batches: 45000
  max_trials: 200 # number of configurations to evaluate
  mode: aggressive
  divisor: 3
min_validation_period:
  batches: 1
checkpoint_storage:
  save_trial_best: 0
  save_trial_latest: 1
  save_experiment_best: 0
resources:
  slots_per_trial: 1
  max_slots: 8
  agent_label: pepper-cluster
max_restarts: 0
environment:
  image:
    cpu: "deepprojects/determined-pytorch-1.10-cpu:1.0.0"
    gpu: "deepprojects/determined-cuda-113-pytorch-1.10-gpu:1.0.0"
bind_mounts:
 - host_path: /data/ldap
   container_path: /data/ldap
   read_only: true
entrypoint: trials:SimSiam