description: PAWS-Kather-Lizard-Transfer-Finetune
name: Kather-Lizard-Transfer::resnet50::Split_Reduce # Split_Reduce, Stability_Experiment
labels:
  - resnet50
  - finetune
  - kather-lizard-transfer
  - 20_Epochs
  - 1.0_Split
data:
  worker: 4
reproducibility:
  experiment_seed: 1643118217 # 1643118217 fixed seed for split reduce
hyperparameters:
  copy_data: false
  use_fp16: true
  method: paws
  # Data
  dataset: lizard
  number_classes: 4
  normalize_data: true
  train_augmentation: light_stack
  test_augmentation: plain
  img_rescale_size: 96
  pred_head_structure:
       type: categorical
       vals:
        - one_layer_mlp   # three_layer_mlp one_layer_mlp
        - three_layer_mlp
  split_size: 
      type: categorical
      vals:
      - 1.0 # (297245*0.08)/32 = 743 --> 20 epochs = 14860 , (297245*1.0)/256 = 1161 --> 20 epochs = 23220
  split_seed: 42
  # Encoder Evaluation
  plot_embedding_each: 1161 # 743, 1161 # 1Epoch
  # Model
  model_name: resnet50 #base model
  dropout_rate: 
      type: categorical
      vals: 
      - 0.0
  use_pred_head: True
  output_dim: 128
  freeze_encoder: 
      type: categorical
      vals:
      - 2972 # 4 epochs on 0.08 split
      - true # if > max length its never trained
  checkpoint_uuid:
      type: categorical
      vals:
      # kather encoder
      - 64ecb7b1-f885-4a29-9536-04e4aa8e8d1b  # 11149 - 81216 0.08,1.0 Split
      #- de9fc489-6960-46c4-83b9-c5543f8899be # 11149 - 81215 0.008 Split
      #- 45433f15-321c-4c56-b938-25a3c128f3fc # 11149 - 81244 0.002 Split
      - null
      # for stability experiments
      #- a6eddd47-425f-4b92-a8e7-a79a67a2479d # Seed 1 - 11546 84089
      #- 0f8c1c69-a06b-4f7c-b820-0ae334398c14 # Seed 2 - 11651 84689
      #- 0f9767a2-28d9-4e67-9e88-35ccea32a3e3 # Seed 3 - 11652 84690
      #- 82c0d973-c448-4369-867b-e8e82982797a # Seed 4 - 11549 84092
      #- cf6b2ab5-4c8f-4432-965b-8f25fe4193f4 # Seed 5 - 11550 84093
  # -- optimizer
  momentum: 0.9
  lr: 
      type: categorical
      vals:
      - 0.005
  weight_decay: 1e-4
  scheduler: true
  use_larc: false
  # -- training 
  global_batch_size: 256 # 32, 256
# Single run without hyperparameter tuning
searcher:
  name: grid
  metric: v_acc
  smaller_is_better: false
  max_length:
    batches: 23220 # 20 Epochs for 0.08 Split with batch size 32 -> 14860, full supervised 23220
min_validation_period:
  batches: 1161 # 743, 1161 # 1Epoch
checkpoint_storage:
  save_trial_best: 1
  save_trial_latest: 1
  save_experiment_best: 0
resources:
  slots_per_trial: 1
  agent_label: dt-cluster #dt-cluster pepper-cluster
  max_slots: 4
max_restarts: 0
# Docker container used
environment:
  image:
    cpu: "deepprojects/determined-pytorch-1.10-cpu:1.0.0"
    gpu: "deepprojects/determined-cuda-113-pytorch-1.10-gpu:1.0.0"
# Bind Avocado into the docker container
bind_mounts:
 - host_path: "/data/determined/shared_fs/checkpoints"
   container_path: "/checkpoints"
   read_only: true
 - host_path: /data/ldap
   container_path: /data/ldap
   read_only: true
entrypoint: finetune_trial:Finetune