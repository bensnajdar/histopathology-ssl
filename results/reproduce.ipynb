{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce Figures and Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from reproduce import reproduce_results\n",
    "\n",
    "# -- Catching pandas slice warnings\n",
    "with warnings.catch_warnings(record=True):\n",
    "    reproduce_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce XAI Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import yaml\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "# -- internal\n",
    "from utils import get_model, get_image_data_list, get_augmentations, XAI_model_wrapper, MAPPINGS \n",
    "\n",
    "# -- Path  collection\n",
    "XAI_CONFIG = 'config/xai_config.yaml'\n",
    "LOCAL_CHECKPOINTS =  'res/checkpoints/'\n",
    "RESULT_PATH = 'plots/xai/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(XAI_CONFIG, \"r\") as file:\n",
    "    xai_data_config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    \n",
    "checkpoint_uuid_list = xai_data_config['checkpoints'] # all on downstream kather for 1-Layer-MLP\n",
    "\n",
    "for checkpoint_uuid in checkpoint_uuid_list:    \n",
    "    # NOTE: Determined checkpoint fetch replaced for docker container\n",
    "    checkpoint_path = Path(LOCAL_CHECKPOINTS, checkpoint_uuid)\n",
    "    with open(Path(checkpoint_path, 'metadata.json'), \"r\") as metadata_file:\n",
    "        mf_tmp = json.load(metadata_file)\n",
    "        checkpoint_configuration = mf_tmp['experiment_config']\n",
    "        checkpoint_hparam = mf_tmp['hparams']\n",
    "    \n",
    "    # -- get augementation that was used for testing process in the downstream task\n",
    "    augmentations = get_augmentations(checkpoint_hparam)\n",
    "    \n",
    "    # -- load checkpoint state dict and init model\n",
    "    state_dict = t.load(Path(checkpoint_path, 'state_dict.pth'), map_location=\"cpu\")['models_state_dict']\n",
    "    model = get_model(checkpoint_uuid, checkpoint_hparam, state_dict)\n",
    "    # model.load_state_dict(state_dict[0])\n",
    "\n",
    "    try:\n",
    "        model_name = checkpoint_hparam['model_name']\n",
    "    except:\n",
    "        model_name = checkpoint_hparam['encoder']\n",
    "    \n",
    "    # -- getting test images to explain\n",
    "    xai_data_list, classes, dataset_name = get_image_data_list(xai_config=xai_data_config, dataset=checkpoint_hparam['dataset'])\n",
    "    \n",
    "    # do XAI \n",
    "    for i,image_path in enumerate(xai_data_list):\n",
    "        test_image = Image.open(image_path)\n",
    "        test_img_tensor = augmentations(test_image).unsqueeze(0)\n",
    "        test_tensor = t.vstack([test_img_tensor, t.ones((1,3,96,96))])\n",
    "        \n",
    "        # -- GradCam\n",
    "        xai_model = XAI_model_wrapper(base_model=model, model_name=model_name).eval()\n",
    "        out = xai_model(test_tensor)[0]\n",
    "        pred = np.argmax(out.detach().cpu().numpy())\n",
    "        out[pred].backward()  # getting features for predicted class\n",
    "        fma = xai_model.fma[0].detach().cpu().numpy()  \n",
    "        fmg = xai_model.fmg[0][0].detach().cpu().numpy()   \n",
    "        fmg_weights = xai_model.get_fmg_weights()[0].detach().numpy()\n",
    "        \n",
    "        Grad_CAM_map = np.zeros((fma.shape[-1],fma.shape[-2]))\n",
    "        for i in range(fmg.shape[0]):\n",
    "            Grad_CAM_map += fmg_weights[i, 0, 0] * fma[i, :, :]\n",
    "        \n",
    "        if (checkpoint_hparam['dataset']=='patchcamelyon'):\n",
    "            Grad_CAM_map = cv2.resize(Grad_CAM_map, dsize=(96,96), interpolation=cv2.INTER_LINEAR )\n",
    "        else:\n",
    "            Grad_CAM_map = cv2.resize(Grad_CAM_map, dsize=(224,224), interpolation=cv2.INTER_LINEAR )\n",
    "        \n",
    "        # -- Guided Backprop\n",
    "        xai_model = XAI_model_wrapper(base_model=model, model_name=model_name).eval()\n",
    "        test_tensor.requires_grad = True\n",
    "        def backward_hook(module, grad_in, grad_out):\n",
    "                if isinstance(module, nn.ReLU):\n",
    "                    return (F.relu(grad_in[0]),)\n",
    "\n",
    "        for module in xai_model.named_modules():\n",
    "            module[1].register_backward_hook(backward_hook)\n",
    "\n",
    "        out = xai_model(test_tensor)[0]\n",
    "        pred = np.argmax(out.detach().cpu().numpy())\n",
    "\n",
    "        test_img_gradient = t.autograd.grad(out[pred],test_tensor, allow_unused=True)[0][0]    \n",
    "        np_test_img_gradient = abs(test_img_gradient.detach().cpu().numpy().transpose(1,2,0))\n",
    "        saliency_map = np.zeros_like(np_test_img_gradient[:,:,0])\n",
    "\n",
    "        for i in range(np_test_img_gradient.shape[0]):\n",
    "            for j in range(np_test_img_gradient.shape[1]):\n",
    "                saliency_map[i,j] = max(np_test_img_gradient[i,j,0],np_test_img_gradient[i,j,1],np_test_img_gradient[i,j,2])\n",
    "\n",
    "        if (checkpoint_hparam['dataset']=='patchcamelyon'):\n",
    "            Guided_Backprop_map = cv2.resize(saliency_map,dsize=(96,96),interpolation=cv2.INTER_LINEAR)\n",
    "        else:\n",
    "            Guided_Backprop_map = cv2.resize(saliency_map,dsize=(224,224),interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        # -- Create plots\n",
    "        fig = plt.figure(figsize=(18,4))\n",
    "        # -- Plain test image\n",
    "        plt.subplot(151)\n",
    "        plt.title('Original Image:'+ image_path.stem, size=12)\n",
    "        plt.xlabel('Prediction: '+classes[pred],size=14)\n",
    "        plt.imshow(test_image)\n",
    "        # -- GradCam heatmap overlay\n",
    "        plt.subplot(152)\n",
    "        plt.title('Grad CAM map', size=14)\n",
    "        plt.imshow(test_image, alpha=0.5)\n",
    "        plt.imshow(Grad_CAM_map, cmap=\"jet\",alpha=0.5)\n",
    "\n",
    "        # -- Thresholded image by GradCam map\n",
    "        norm_GGC = (Grad_CAM_map-Grad_CAM_map.min())/np.ptp(Grad_CAM_map)\n",
    "        strength_add = (norm_GGC > (0.6 * norm_GGC.max())) * 1.0\n",
    "        weaken_sub = (norm_GGC < (1.0 * norm_GGC.mean())) * 1.0\n",
    "        norm_GGC_sa = np.add(norm_GGC, strength_add)\n",
    "        norm_GGC_sa_ws = np.subtract(norm_GGC_sa, weaken_sub)\n",
    "        alphas_ = np.clip(norm_GGC_sa_ws, .0, 1.0)\n",
    "        alphas_2 = np.expand_dims(alphas_, axis=2)\n",
    "        test_image_trans = np.concatenate((np.array(test_image)/255,alphas_2),axis=2)\n",
    "        plt.subplot(153)\n",
    "        plt.title('Grad CAM Transparency', size=14)\n",
    "        plt.imshow(test_image_trans)\n",
    "        \n",
    "        # -- Guided-Backprop map\n",
    "        plt.subplot(154)\n",
    "        plt.title('Guided Backprop map', size=14)\n",
    "        plt.imshow(test_image, alpha=0.5)\n",
    "        plt.imshow(Guided_Backprop_map, cmap=\"jet\", alpha=0.5)\n",
    "\n",
    "        # -- Guide-GradCam map\n",
    "        Guided_Grad_CAM_map = Grad_CAM_map * Guided_Backprop_map\n",
    "        plt.subplot(155)\n",
    "        plt.title('Guided Grad CAM map', size=14)\n",
    "        plt.imshow(test_image, alpha=0.6)\n",
    "        plt.imshow(Guided_Grad_CAM_map, cmap=\"jet\",alpha=0.6)\n",
    "\n",
    "        # -- Name and persist\n",
    "        if checkpoint_hparam['checkpoint_uuid']:\n",
    "            general_label = checkpoint_hparam['method'] + '_' + MAPPINGS['encoder_dataset'][checkpoint_hparam['checkpoint_uuid']] + '_'\n",
    "        else:\n",
    "            general_label = 'supervised_'\n",
    "        general_label += MAPPINGS['dataset'][checkpoint_hparam['dataset']] + '_' + checkpoint_hparam['pred_head_structure']\n",
    "\n",
    "        fig.suptitle(general_label, size=16)\n",
    "\n",
    "        image_folder = Path(RESULT_PATH, dataset_name, image_path.stem, MAPPINGS['freeze'][checkpoint_hparam['freeze_encoder']])\n",
    "        if not os.path.exists(image_folder):\n",
    "            os.makedirs(image_folder)\n",
    "\n",
    "        fig.savefig(Path(image_folder).joinpath(general_label + '.png'), dpi=100)\n",
    "        plt.close()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
