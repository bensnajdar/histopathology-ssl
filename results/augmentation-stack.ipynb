{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to visualize the augmentation stacks used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from cbmi_utils.pytorch.datasets.kather import Kather224x224, Kather96x96\n",
    "from PIL import Image\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
    "# if you change the seed, make sure that the randomly-applied transforms\n",
    "# properly show that the image can be both transformed and *not* transformed!\n",
    "torch.manual_seed(5)\n",
    "px = 2\n",
    "dataset = 'kather224'\n",
    "orig_img = Image.open(Path('./plots/augmentations/TUM-YVGHNMGQ.tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(imgs, with_orig=True, row_title=None, **imshow_kwargs):\n",
    "    if not isinstance(imgs[0], list):\n",
    "        # Make a 2d grid even if there's just 1 row\n",
    "        imgs = [imgs]\n",
    "\n",
    "    num_rows = len(imgs)\n",
    "    num_cols = len(imgs[0]) + with_orig\n",
    "    fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, squeeze=True, figsize=(num_cols * px, num_rows * px))\n",
    "    \n",
    "    \n",
    "    for row_idx, row in enumerate(imgs):\n",
    "        row = [orig_img] + row if with_orig else row\n",
    "        for col_idx, img in enumerate(row):\n",
    "            ax = axs[row_idx, col_idx]\n",
    "            ax.imshow(np.asarray(img), **imshow_kwargs)\n",
    "            ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "    if with_orig:\n",
    "        axs[0, 0].set(title='Image')\n",
    "        axs[0, 0].title.set_size(9*px)\n",
    "        for i in range(num_cols-1):\n",
    "            axs[0, i+1].set(title=f'View {i+1}')\n",
    "            axs[0, i+1].title.set_size(9*px)\n",
    "\n",
    "    if row_title is not None:\n",
    "        for row_idx in range(num_rows):\n",
    "            axs[row_idx, 0].set_ylabel(row_title[row_idx], fontsize = 9*px)\n",
    "\n",
    "    # plt.subplots_adjust(top=0.2, bottom=0.1, right=0.1, left=0.005)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm_values(ds: str):\n",
    "    ds = ds.lower()\n",
    "    if any(substr in ds for substr in (\"kather_h5_224\", \"kather224\", \"kather_if_224\")):\n",
    "        mean, std = Kather224x224.normalization_values()\n",
    "    elif any(substr in ds for substr in (\"kather_h5_96\", \"kather96\")):\n",
    "        mean, std = Kather96x96.normalization_values()\n",
    "    else:\n",
    "        raise NotImplementedError(f'Request of normalization constants of {ds} is not implemented!')\n",
    "\n",
    "    return mean, std\n",
    "    \n",
    "\n",
    "def light_stack(dataset, normalize: bool = False, img_size: int = 224):\n",
    "\n",
    "    transform_pre_norm = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(\n",
    "                brightness=[0.9, 1.1],\n",
    "                contrast=0,\n",
    "                saturation=[0.7, 1.8],\n",
    "                hue=0\n",
    "            )  # not strengthened\n",
    "        ], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "    ])\n",
    "\n",
    "    transform_post_norm = transforms.Compose([\n",
    "        transforms.RandomApply([\n",
    "            transforms.RandomCrop(img_size * .9),\n",
    "            transforms.Resize(img_size)\n",
    "        ], p=0.5),\n",
    "        transforms.RandomApply([\n",
    "            transforms.Resize(int(img_size * (2**0.5) + 0.9999)),\n",
    "            transforms.RandomRotation(180)\n",
    "        ], p=0.8),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.ToPILImage()\n",
    "    ])\n",
    "\n",
    "    if normalize:\n",
    "        mean, std = get_norm_values(dataset)\n",
    "        return transforms.Compose([transform_pre_norm, transforms.Normalize(mean, std), transform_post_norm])\n",
    "    else:\n",
    "        return transforms.Compose([transform_pre_norm, transform_post_norm])\n",
    "\n",
    "\n",
    "def medium_stack(dataset, normalize: bool = False, img_size: int = 224):\n",
    "\n",
    "    transform_pre_norm = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n",
    "        ], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "    ])\n",
    "\n",
    "    transform_post_norm = transforms.Compose([\n",
    "        transforms.RandomApply([\n",
    "            transforms.RandomCrop(img_size * .9),\n",
    "            transforms.Resize(img_size)\n",
    "        ], p=0.5),\n",
    "        transforms.RandomApply([\n",
    "            transforms.Resize(int(img_size * (2**0.5) + 0.9999)),\n",
    "            transforms.RandomRotation(180)\n",
    "        ], p=0.8),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomApply([\n",
    "            transforms.GaussianBlur(kernel_size=img_size // 20 * 2 + 1, sigma=(0.1, 2.0))\n",
    "        ], p=0.5),\n",
    "        transforms.ToPILImage()\n",
    "    ])\n",
    "\n",
    "    if normalize:\n",
    "        mean, std = get_norm_values(dataset)\n",
    "        return transforms.Compose([transform_pre_norm, transforms.Normalize(mean, std), transform_post_norm])\n",
    "    else:\n",
    "        return transforms.Compose([transform_pre_norm, transform_post_norm])\n",
    "\n",
    "\n",
    "def moco_v2(dataset, normalize: bool = False, img_size: int = 224):\n",
    "    augmentations = [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomResizedCrop(img_size, scale=(0.2, 1.0)),\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n",
    "        ], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        # We blur the image 50% of the time using a Gaussian kernel. We randomly sample σ ∈ [0.1, 2.0], and the kernel size is set to be 10% of the image height/width.\n",
    "        transforms.RandomApply([\n",
    "            transforms.GaussianBlur(kernel_size=img_size // 20 * 2 + 1, sigma=(0.1, 2.0))\n",
    "        ], p=0.5),\n",
    "        transforms.RandomHorizontalFlip()\n",
    "    ]\n",
    "\n",
    "    if normalize:\n",
    "        mean, std = get_norm_values(dataset)\n",
    "        augmentations.append(transforms.Normalize(mean, std))\n",
    "    \n",
    "    augmentations.append(transforms.ToPILImage())\n",
    "    return transforms.Compose(augmentations)\n",
    "\n",
    "import PIL\n",
    "\n",
    "def paws(img_size=224, size=18, scale=(0.3, 0.75), normalize=False, color_distortion=0.5):\n",
    "    def get_color_distortion(s=1.0):\n",
    "        # s is the strength of color distortion.\n",
    "        color_jitter = transforms.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)\n",
    "        rnd_color_jitter = transforms.RandomApply([color_jitter], p=0.8)\n",
    "\n",
    "        def Solarize(img):\n",
    "            v = np.random.uniform(0, 256)\n",
    "            return PIL.ImageOps.solarize(img, v)\n",
    "        solarize = transforms.Lambda(Solarize)\n",
    "        rnd_solarize = transforms.RandomApply([solarize], p=0.2)\n",
    "\n",
    "        def Equalize(img):\n",
    "            return PIL.ImageOps.equalize(img)\n",
    "        equalize = transforms.Lambda(Equalize)\n",
    "        rnd_equalize = transforms.RandomApply([equalize], p=0.2)\n",
    "\n",
    "        color_distort = transforms.Compose([\n",
    "            rnd_color_jitter,\n",
    "            rnd_solarize,\n",
    "            rnd_equalize])\n",
    "        return color_distort\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "            transforms.Resize(int(img_size)),\n",
    "            transforms.Resize(int(img_size*(2**0.5)+0.9999)),\n",
    "            transforms.RandomRotation(180),\n",
    "            transforms.RandomResizedCrop(size=size, scale=scale),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            get_color_distortion(s=color_distortion)\n",
    "        ])\n",
    "\n",
    "    if normalize:\n",
    "        transform = transforms.Compose([\n",
    "            transform,\n",
    "            transforms.Normalize(\n",
    "                    (0.7455422, 0.52883655, 0.70516384),\n",
    "                    (0.15424888, 0.20247863, 0.14497302)\n",
    "                )\n",
    "        ])  \n",
    "    return transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# noinspection PyPackageRequirements\n",
    "import torchvision.transforms.functional as functional\n",
    "# noinspection PyPackageRequirements\n",
    "from torchvision import transforms as torch_transforms\n",
    "from typing import Sequence, Tuple, Optional\n",
    "import random\n",
    "\n",
    "\n",
    "# copied from: https://github.com/pytorch/vision/issues/566#issuecomment-535854734\n",
    "class RotateTransform:\n",
    "    def __init__(self, angles: Sequence[int], use_flip=True):\n",
    "        self.angles = angles\n",
    "        self.flip = None\n",
    "        if use_flip:\n",
    "            self.flip = torch_transforms.RandomHorizontalFlip(p=0.5)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        angle = random.choice(self.angles)\n",
    "        if angle:\n",
    "            return functional.rotate(x, angle)\n",
    "        if self.flip:\n",
    "            x = self.flip(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RandomGaussianBlur:\n",
    "    def __init__(self, kernel_size, p=0.5, sigma=(0.1, 2.0)):\n",
    "        self.blur = torch_transforms.RandomApply(\n",
    "            [torch_transforms.GaussianBlur(kernel_size, sigma)],\n",
    "            p=p\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.blur(x)\n",
    "\n",
    "\n",
    "class Noise:\n",
    "    def __init__(self, strength):\n",
    "        self.strength = strength\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return x + torch.randn_like(x) * self.strength\n",
    "\n",
    "\n",
    "class ColorDistort:\n",
    "    def __init__(self, jitter_strength, jitter_p=0.8, grayscale_p=0.2):\n",
    "        self.grayscale = torch_transforms.RandomGrayscale(p=grayscale_p)\n",
    "        self.color_jitter = torch_transforms.RandomApply(\n",
    "            [torch_transforms.ColorJitter(\n",
    "                brightness=0.8*jitter_strength,\n",
    "                saturation=0.8*jitter_strength,\n",
    "                contrast=0.8*jitter_strength,\n",
    "                hue=0.2*jitter_strength,\n",
    "            )],\n",
    "            p=jitter_p\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.grayscale(self.color_jitter(x))\n",
    "\n",
    "\n",
    "class Clamp:\n",
    "    def __call__(self, x):\n",
    "        return x.clamp(0.0, 1.0)\n",
    "\n",
    "\n",
    "class Cutout:\n",
    "    def __init__(self, size: Optional[Tuple[int, int]] = None, color: float = 0.5, quadratic: bool = True):\n",
    "        \"\"\"\n",
    "        Creates a new Cutout augmentation.\n",
    "\n",
    "        :param size: A tuple (min, max) defining the size of the cutout. The actual size of the cutout is than randomly\n",
    "                     sampled for each image (min <= size <= max). If not given, it defaults to (0, img_size).\n",
    "        :param color: The brightness of the gray color that is used for the cutout. 0.0 means black and 1.0 means white.\n",
    "                      Defaults to 0.5.\n",
    "        :param quadratic: Whether the cutout should be quadratic. Defaults to True.\n",
    "        \"\"\"\n",
    "        self.size = size\n",
    "        self.color = color\n",
    "        self.quadratic = quadratic\n",
    "\n",
    "    def __call__(self, img):\n",
    "        size = self.size\n",
    "        if size is None:\n",
    "            size = (0, min(img.size()[1], img.size()[2]))\n",
    "        size_y = random.randint(size[0], size[1])\n",
    "        pos_y = random.randint(0, img.size()[1] - size_y)\n",
    "        if self.quadratic:\n",
    "            size_x = size_y\n",
    "        else:\n",
    "            size_x = random.randint(size[0], size[1])\n",
    "        pos_x = random.randint(0, img.size()[2] - size_x)\n",
    "        img = img.detach().clone()\n",
    "        img[:, pos_y:pos_y+size_y, pos_x:pos_x+size_x] = self.color\n",
    "        return img\n",
    "\n",
    "\n",
    "\n",
    "DEFAULT_COLOR_JITTER_BRIGHTNESS = 0.2\n",
    "DEFAULT_COLOR_JITTER_SATURATION = 0.2\n",
    "DEFAULT_COLOR_JITTER_HUE = 0.2\n",
    "DEFAULT_RANDOM_RESIZED_CROP_SCALE = (0.08, 1.0)\n",
    "\n",
    "\n",
    "def _entry_to_transform(entry, slide_size):\n",
    "    if entry == 'color_distort':\n",
    "        return ColorDistort(\n",
    "            jitter_strength=1.0,\n",
    "            jitter_p=0.8,\n",
    "            grayscale_p=0.2,\n",
    "        )\n",
    "    elif entry == 'random_crop':\n",
    "        return torch_transforms.RandomResizedCrop(\n",
    "                size=slide_size,\n",
    "                scale=DEFAULT_RANDOM_RESIZED_CROP_SCALE\n",
    "            )\n",
    "    elif entry == 'cutout':\n",
    "        return Cutout(size=(40, 50))\n",
    "    elif entry == 'blur':\n",
    "        return RandomGaussianBlur(kernel_size=23, p=0.5)\n",
    "    elif entry == 'rotate':\n",
    "        return RotateTransform([0, 90, 180, 270])\n",
    "    elif entry == 'noise':\n",
    "        return Noise(strength=0.2)\n",
    "    elif entry == 'affine':\n",
    "        return torch_transforms.RandomAffine(\n",
    "            degrees=(-180, 180), translate=None,\n",
    "            scale=(0.7, 1.3), shear=(-10, 10, -10, 10)\n",
    "        )\n",
    "    elif entry == 'color_jitter':\n",
    "        raise ValueError('color jitter was replaced by color_distort')\n",
    "    elif entry == 'color_drop':\n",
    "        raise ValueError('color drop was replaced by color_distort')\n",
    "    else:\n",
    "        raise ValueError('Could not load transform \"{}\"'.format(entry))\n",
    "\n",
    "\n",
    "def description_to_transform(augmentations, slide_size, use_rotation, use_clamp, image_rescale_size):\n",
    "    transforms_list = [torch_transforms.ToTensor()]\n",
    "    if use_rotation:\n",
    "        transforms_list.append(RotateTransform([0, 90, 180, 270]))\n",
    "    for entry in augmentations:\n",
    "        if use_rotation and entry == 'rotate':\n",
    "            raise AssertionError('got rotate as augmentation and entry')\n",
    "        transforms_list.append(_entry_to_transform(entry, slide_size))\n",
    "\n",
    "    if use_clamp:\n",
    "        transforms_list.append(Clamp())\n",
    "\n",
    "    if image_rescale_size is not None:\n",
    "        transforms_list.append(torch_transforms.Resize(image_rescale_size))\n",
    "\n",
    "    transforms_list.append(torch_transforms.ToPILImage())\n",
    "    return torch_transforms.Compose(transforms_list)\n",
    "\n",
    "\n",
    "def make_unique(l):\n",
    "    unique = []\n",
    "    for i in l:\n",
    "        if i not in unique:\n",
    "            unique.append(i)\n",
    "    return unique\n",
    "\n",
    "\n",
    "def sim_clr(augmentations, slide_size, use_rotation=False, use_clamp=True, image_rescale_size=None):\n",
    "    augmentations = make_unique(augmentations)\n",
    "    return description_to_transform(augmentations, slide_size, use_rotation, use_clamp, image_rescale_size)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aug_stacks = [\n",
    "    light_stack(dataset), \n",
    "    moco_v2(dataset), \n",
    "    medium_stack(dataset), \n",
    "    paws(\n",
    "        size=96,\n",
    "        scale=(0.6,0.9),\n",
    "        color_distortion=0.5\n",
    "        ),\n",
    "    sim_clr(\n",
    "            augmentations=('color_distort', 'random_crop'),\n",
    "            slide_size=(224,224),\n",
    "            use_rotation=True,\n",
    "            image_rescale_size=(224, 224)\n",
    "        )\n",
    "    ]\n",
    "\n",
    "\n",
    "stack_title = ['Custom', 'Moco_v2', 'Ad. Moco_v2', 'Ad. Paws', 'Ad. SimCLR']\n",
    "\n",
    "imgs = [[aug(orig_img) for _ in range(8)] for aug in aug_stacks]\n",
    "\n",
    "plot(imgs, row_title=stack_title)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
